# 0) Prereqs

- Node 20+
- npm (bundled with Node)
- (Optional) Supabase account OR Docker Desktop for local Supabase

---

# 1) Create the app

```bash
npx create-next-app@latest ./ --ts --app --eslint
cd ai-interviews
```

---

# 2) Add Chakra v3 + Panda CSS

```bash
npm i @chakra-ui/react
npm i -D @pandacss/dev
npx panda init
```

Edit `panda.config.ts`:

```ts
// panda.config.ts
import { defineConfig } from "@pandacss/dev";

export default defineConfig({
  presets: ["@pandacss/preset-base", "@pandacss/preset-panda"],
  include: ["./src/**/*.{ts,tsx}", "./app/**/*.{ts,tsx}"],
  outdir: "styled-system",
});
```

Add scripts to `package.json`:

```json
{
  "scripts": {
    "dev": "next dev",
    "build": "npm run build:panda && next build",
    "start": "next start",
    "build:panda": "panda codegen",
    "panda": "panda codegen --watch"
  }
}
```

Create the Chakra provider:

```tsx
// app/providers.tsx
"use client";
import { ChakraProvider } from "@chakra-ui/react";

export default function Providers({ children }: { children: React.ReactNode }) {
  return <ChakraProvider>{children}</ChakraProvider>;
}
```

Wire Panda CSS + Provider:

```tsx
// app/layout.tsx
import "./globals.css";
import "../styled-system/styles.css"; // generated by Panda after first run
import Providers from "./providers";

export const metadata = { title: "AI Interviews (POC)" };

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body>
        <Providers>{children}</Providers>
      </body>
    </html>
  );
}
```

Quick home page:

```tsx
// app/page.tsx
import { Button, Container, Heading, Text } from "@chakra-ui/react";

export default function Home() {
  return (
    <Container py={10}>
      <Heading size="lg">AI Interview Avatars (POC)</Heading>
      <Text mt={3}>Practice interviews with simple AI avatars.</Text>
      <Button mt={6} as="a" href="/interview">
        Start interview
      </Button>
    </Container>
  );
}
```

Run Panda and the dev server (two terminals):

```bash
npm run panda
# new terminal
npm run dev
```

---

# 3) Supabase (Auth + DB)

Install client:

```bash
npm i @supabase/supabase-js
```

Env file:

```bash
# .env.local
NEXT_PUBLIC_SUPABASE_URL=your_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_key   # server-only, don't expose to browser
```

Client helper:

```ts
// src/lib/supabase.ts
import { createClient } from "@supabase/supabase-js";

export const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
);
```

(For the POC, you can skip auth screens entirely and just store messages; add auth later if you want.)

Create minimal tables (run in Supabase SQL editor):

```sql
create table if not exists avatars (
  id uuid primary key default gen_random_uuid(),
  name text not null,
  system_prompt text not null,
  version int not null default 1,
  created_at timestamptz default now()
);

create table if not exists interviews (
  id uuid primary key default gen_random_uuid(),
  title text,
  avatar_id uuid references avatars(id),
  status text check (status in ('draft','in_progress','submitted','reviewed')) default 'draft',
  prompt_version_used int default 1,
  created_at timestamptz default now()
);

create table if not exists messages (
  id bigserial primary key,
  interview_id uuid references interviews(id) on delete cascade,
  role text check (role in ('user','assistant')) not null,
  text text not null,
  created_at timestamptz default now()
);
```

> POC tip: leave RLS off for now to reduce friction.

Seed one avatar (optional):

```sql
insert into avatars (name, system_prompt) values
('Friendly Recruiter', 'You are a helpful recruiter. Ask concise interview questions and give actionable hints.');
```

---

# 4) OpenAI streaming (super simple)

Install:

```bash
npm i openai
```

Env:

```bash
# .env.local
OPENAI_API_KEY=your_openai_key
OPENAI_MODEL=gpt-4o-mini
```

Streaming route (chunks via `fetch` readable stream):

```ts
// app/api/stream/route.ts
import { NextRequest } from "next/server";
import OpenAI from "openai";

export const runtime = "nodejs";

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

export async function POST(req: NextRequest) {
  const { messages } = await req.json(); // [{role:"user"|"assistant", content:string}]
  const result = await client.chat.completions.create({
    model: process.env.OPENAI_MODEL || "gpt-4o-mini",
    messages,
    stream: true,
  });

  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      try {
        for await (const part of result) {
          const delta = part.choices?.[0]?.delta?.content || "";
          if (delta) controller.enqueue(encoder.encode(delta));
        }
      } finally {
        controller.close();
      }
    },
  });

  return new Response(stream, {
    headers: { "Content-Type": "text/plain; charset=utf-8" },
  });
}
```

Tiny helper to read the stream:

```ts
// src/lib/streamCompletion.ts
export async function* streamCompletion(messages: any[]) {
  const res = await fetch("/api/stream", {
    method: "POST",
    body: JSON.stringify({ messages }),
  });
  const reader = res.body!.getReader();
  const dec = new TextDecoder();
  while (true) {
    const { value, done } = await reader.read();
    if (done) break;
    yield dec.decode(value);
  }
}
```

Minimal interview UI:

```tsx
// app/interview/page.tsx
"use client";
import { useState } from "react";
import { Box, Button, HStack, Input, Stack, Text } from "@chakra-ui/react";
import { streamCompletion } from "@/src/lib/streamCompletion";

type Msg = { role: "user" | "assistant"; content: string };

export default function InterviewPage() {
  const [msgs, setMsgs] = useState<Msg[]>([]);
  const [input, setInput] = useState("");

  async function send() {
    if (!input.trim()) return;
    const history = [...msgs, { role: "user", content: input }];
    setMsgs(history);
    setInput("");

    let acc = "";
    for await (const chunk of streamCompletion(history)) {
      acc += chunk;
      setMsgs([...history, { role: "assistant", content: acc }]);
    }
  }

  return (
    <Stack p={6} gap={4}>
      <Box borderWidth="1px" rounded="xl" p={4} minH="280px">
        {msgs.map((m, i) => (
          <Text key={i} mb={2}>
            <b>{m.role}:</b> {m.content}
          </Text>
        ))}
      </Box>
      <HStack>
        <Input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Ask the avatar..."
          onKeyDown={(e) => (e.key === "Enter" ? send() : null)}
        />
        <Button onClick={send}>Send</Button>
      </HStack>
    </Stack>
  );
}
```

---

# 5) Save messages to Supabase (POC)

```ts
// app/api/messages/route.ts
import { NextRequest } from "next/server";
import { createClient } from "@supabase/supabase-js";

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
);

export async function POST(req: NextRequest) {
  const body = await req.json(); // { interview_id, role, text }
  const { error } = await supabase.from("messages").insert(body);
  if (error) return Response.json({ error: error.message }, { status: 400 });
  return Response.json({ ok: true });
}
```

> Call this after each user/assistant message if you want persistence now, or add later.

---

# 6) Run it

Two terminals:

```bash
npm run panda
# new terminal
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) and try **Start interview**.

---

# 7) Folder structure (final POC)

```
ai-interviews/
  app/
    api/
      messages/
        route.ts
      stream/
        route.ts
    interview/
      page.tsx
    layout.tsx
    page.tsx
    providers.tsx
  src/
    lib/
      streamCompletion.ts
      supabase.ts
  styled-system/          # generated by Panda after first run
  panda.config.ts
  package.json
  tsconfig.json
  .env.local
  next.config.mjs
  README.md
```

---

# 8) (Optional) Dockerfile

```dockerfile
# Dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build:panda && npm run build
EXPOSE 3000
CMD ["npm","start"]
```

---

## That’s it

You’ve got a clean POC with **npm**, Next.js, Chakra v3+Panda, OpenAI streaming, and optional Supabase storage.
Want me to add a tiny **seed script** (1 interview + sample messages) or a barebones **login** later?
